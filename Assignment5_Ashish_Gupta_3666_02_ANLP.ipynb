{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Assignment5_Ashish_Gupta_3666_02_ANLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcxigOy7C9k5",
        "colab_type": "text"
      },
      "source": [
        "You will be building a movie category prediction model using 2 different supervised machine learning algorithms of your choice and provides which algorithm does give the best evaluation result with 10-fold cross validation. You need to print the following information as the outcome of your work:\n",
        "\n",
        "Print the Precision, Recall, Accuracy, and F1 score for all those algorithms you used\n",
        "Let the examiner know which model you think is best performing and why\n",
        " \n",
        "\n",
        "Input Dat Set:\n",
        "\n",
        "You will be using the CMU Movie Summary Corpus (Links to an external site.) data (open data) for this assignment. You can also directly download the dataset from here (Links to an external site.). You need to use only following two data files for this assignment:\n",
        "\n",
        "* movie.metadata.tsv: You will be getting target variable data from here. Please extract Movie_Genre tag for that.\n",
        "\n",
        "* plot_summaries.txt: This file contains the Plot Summaries for every movie in text form.  Each record contains a Movie ID which does index with movie.metadata.tsv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfVve7emC9lA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import chardet\n",
        "import re as re\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from __future__ import division\n",
        "\n",
        "#some useful distributions\n",
        "from scipy.stats import expon as sp_expon\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import uniform as sp_uniform\n",
        "\n",
        "#sklearn utilities\n",
        "from sklearn.base import MetaEstimatorMixin,BaseEstimator, TransformerMixin,ClassifierMixin\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, SelectPercentile, chi2, f_classif, mutual_info_classif\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer, MultiLabelBinarizer\n",
        "\n",
        "\n",
        "#Models  \n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import LinearSVC, SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqjKgmWxC9lU",
        "colab_type": "text"
      },
      "source": [
        "## 1. Importing Movie Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quPDxBjBGkjl",
        "colab_type": "code",
        "outputId": "889da447-5598-4982-8edc-b209165de06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QABWZt2mGvZ4",
        "colab_type": "code",
        "outputId": "79ff0384-50f1-4b01-fb57-b09ec51fd34d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/movies/\")\n",
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['plot_summaries.txt', 'movie.metadata.tsv', 'test.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HhrkPRFC9la",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movieData = pd.read_csv('movie.metadata.tsv', sep='\\t', header=0, encoding='utf-8',\n",
        "                        names=[\"WikipediaID\", \"FreebaseID\", \"name\", \"date\", \"boxOffice\", \"runtime\",\n",
        "                               \"languages\", \"countries\", \"genres\"],\n",
        "                        usecols=[\"WikipediaID\", \"name\", \"date\", \"languages\", \"countries\", \"genres\"],\n",
        "                        index_col=0)\n",
        "movieData.dropna(subset=['genres'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7aK7AmtC9lj",
        "colab_type": "text"
      },
      "source": [
        "Exploring Movie Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsHUs-GzC9lm",
        "colab_type": "code",
        "outputId": "f38c0d12-0fa9-4fc4-90d2-01eb617f905d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "movieData.loc[31186339]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name                                          The Hunger Games\n",
              "date                                                2012-03-12\n",
              "languages                   {\"/m/02h40lc\": \"English Language\"}\n",
              "countries            {\"/m/09c7w0\": \"United States of America\"}\n",
              "genres       {\"/m/03btsm8\": \"Action/Adventure\", \"/m/06n90\":...\n",
              "Name: 31186339, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ueu_fmLGC9lt",
        "colab_type": "text"
      },
      "source": [
        "Lets look deep into The genre information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Ssk3uJC9lw",
        "colab_type": "code",
        "outputId": "228aa486-6e46-4231-88b6-d7e31c7ee80c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def extractGenreTags(string):\n",
        "    return re.findall('\"([\\w\\s]+)\"', string)\n",
        "\n",
        "movieData[\"genres\"] = movieData[\"genres\"].apply(extractGenreTags)\n",
        "movieData[\"genres\"].loc[31186339]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Science Fiction', 'Action', 'Drama']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6zs5FoLC9l7",
        "colab_type": "text"
      },
      "source": [
        "That looks like what we need for the Genre. We can now apply this function to our movie data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhMgglrHC9mO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movieData[\"languages\"] = movieData[\"languages\"].apply(extractGenreTags)\n",
        "movieData[\"countries\"] = movieData[\"countries\"].apply(extractGenreTags)\n",
        "\n",
        "isEnglish = lambda languages : u'English Language' in languages\n",
        "movieData = movieData[movieData.languages.apply(isEnglish)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaESjpMRC9mT",
        "colab_type": "text"
      },
      "source": [
        "Now we will import the synopsis data that we will use to predict the genres. First let's check the encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wb6NVbJC9mU",
        "colab_type": "code",
        "outputId": "fd5dfb0d-f9f2-476e-cd6a-fbd670a041d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "file_object  = open('plot_summaries.txt', 'r')\n",
        "print (file_object.read(500))\n",
        "rawdata = file_object.read()\n",
        "chardet.detect(rawdata.encode())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23890098\tShlykov, a hard-working taxi driver and Lyosha, a saxophonist, develop a bizarre love-hate relationship, and despite their prejudices, realize they aren't so different after all.\n",
            "31186339\tThe nation of Panem consists of a wealthy Capitol and twelve poorer districts. As punishment for a past rebellion, each district must provide a boy and girl  between the ages of 12 and 18 selected by lottery  for the annual Hunger Games. The tributes must fight to the death in an arena; the sole surviv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'confidence': 0.99, 'encoding': 'utf-8', 'language': ''}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PjoxGkxC9mb",
        "colab_type": "text"
      },
      "source": [
        "Confident that the data is in the standard utf-8 format, let's import the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVC0RCEhC9me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot = pd.read_csv(\"plot_summaries.txt\", sep='\\t', encoding='utf-8', \n",
        "                   names=[\"ident\", \"synopsis\"], index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2imQFQWC9mj",
        "colab_type": "text"
      },
      "source": [
        "The summary data simply contains the ID number and the synopsis, e.g."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4TiYzgvC9mk",
        "colab_type": "code",
        "outputId": "2c490a08-2b92-4724-8423-0e87524b68cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "plot.loc[31186339]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "synopsis    The nation of Panem consists of a wealthy Capi...\n",
              "Name: 31186339, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGbUlESnC9ms",
        "colab_type": "text"
      },
      "source": [
        "Now let's combine the two files, pairing each movie with its synopsis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slHZfINLC9mt",
        "colab_type": "code",
        "outputId": "47dfd00a-bac8-4fad-dd87-eae20b141ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = pd.merge(movieData, plot, left_index=True, right_index=True, how='inner')\n",
        "result.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24774, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk3uv8WaXYnr",
        "colab_type": "code",
        "outputId": "fa79ec1b-c0da-4626-b3c1-ef9122192ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "result.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>languages</th>\n",
              "      <th>countries</th>\n",
              "      <th>genres</th>\n",
              "      <th>synopsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9363483</th>\n",
              "      <td>White Of The Eye</td>\n",
              "      <td>1987</td>\n",
              "      <td>[English Language]</td>\n",
              "      <td>[United Kingdom]</td>\n",
              "      <td>[Thriller, Erotic thriller, Psychological thri...</td>\n",
              "      <td>A series of murders of rich young women throug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18998739</th>\n",
              "      <td>The Sorcerer's Apprentice</td>\n",
              "      <td>2002</td>\n",
              "      <td>[English Language]</td>\n",
              "      <td>[South Africa]</td>\n",
              "      <td>[Family Film, Fantasy, Adventure, World cinema]</td>\n",
              "      <td>Every hundred years, the evil Morgana  returns...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6631279</th>\n",
              "      <td>Little city</td>\n",
              "      <td>1997-04-04</td>\n",
              "      <td>[English Language]</td>\n",
              "      <td>[United States of America]</td>\n",
              "      <td>[Romantic comedy, Ensemble Film, Drama, Comedy...</td>\n",
              "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               name  ...                                           synopsis\n",
              "9363483            White Of The Eye  ...  A series of murders of rich young women throug...\n",
              "18998739  The Sorcerer's Apprentice  ...  Every hundred years, the evil Morgana  returns...\n",
              "6631279                 Little city  ...  Adam, a San Francisco-based artist who works a...\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYZL_5GyC9m1",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the training labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJGDtjijC9m3",
        "colab_type": "text"
      },
      "source": [
        "We first need to transform the training labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7EnupLUC9m6",
        "colab_type": "code",
        "outputId": "329313e9-82d1-4bc3-9362-1df2bc2ff816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "result.genres[:1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9363483    [Thriller, Erotic thriller, Psychological thri...\n",
              "Name: genres, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEJ0c-FhC9nC",
        "colab_type": "text"
      },
      "source": [
        "These labels need to be binarized so that each genre is represented by a column and a film with a given genre is represented by a 1 in the approriate column. However there are over 300 genres listed in the wikipedia data and not all of them are what we might typically think of as a genre. They can be a detail of the movie content such as 'Airplanes and airports', tell you the place or language of the movie, like 'Bengali Cinema', or even the ditribution, e.g. u'Roadshow theatrical release'. Such descriptions are not really genres and so should be removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGFZuFlCC9nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toDelete = ['Absurdism', 'Airplanes and airports', 'Albino bias','Americana','Animal Picture','Animals','Anthology', 'Anthropology', 'Archaeology','Archives and records','Art film', 'Beach Film','Beach Party film', 'Bengali Cinema','Blaxploitation', 'Bollywood','British Empire Film', 'British New Wave','Buddy film','Business', 'Camp','Cavalry Film', 'Chase Movie', 'Chinese Movies','Christmas movie','Cold War','Coming of age', 'Computers','Cult','Cyberpunk', 'Dogme 95', \n",
        "            'Doomsday film','Early Black Cinema','Education', 'Educational', 'Environmental Science','Ensemble Film', 'Escape Film', 'Essay Film', 'Existentialism','Experimental film', 'Exploitation', 'Expressionism', 'Fan film', 'Feature film', 'Female buddy film', 'Feminist Film', 'Fictional film', 'Filipino', 'Filipino Movies', 'Film', 'Film adaptation','Filmed Play', 'Foreign legion','Giallo','Goat gland', 'Gothic Film','Gross out','Hagiography', 'Holiday Film', 'Indie', 'Japanese Movies', 'Journalism','Jungle Film', 'Juvenile Delinquency Film',\n",
        "            'Kafkaesque', 'Kitchen sink realism', 'Latino', 'Libraries and librarians', 'Linguistics','Live action','Media Studies','Medical fiction','Mondo film','Movie serial','Mumblecore','Nature','New Hollywood', 'News','Northern', 'Nuclear warfare', 'Parkour in popular culture','Patriotic film', 'Pinku eiga', 'Plague', 'Point of view shot','Prison','Private military company','Propaganda film','Reboot', 'Remake', 'Religious Film','Roadshow theatrical release',\n",
        "            'School story', 'Sexploitation', 'Sponsored film', 'Short Film','Singing cowboy', 'Slice of life story','Social issues', 'Social problem film', 'Sponsored film', 'Star vehicle','Statutory rape', 'Steampunk', 'Stoner film','Superhero', 'Superhero movie', 'Surrealism','Sword and Sandal', 'Sword and sorcery', 'Sword and sorcery films',  'Television movie', 'The Netherlands in World War II','Tragedy', 'Travel', 'World cinema', 'Wuxia','Z movie'] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjOR1RQFC9nJ",
        "colab_type": "text"
      },
      "source": [
        "The genre listed can be a combination of several genres and so should be categorized seperately. This means replacing 'Action Comedy' with 'Action' and 'Comedy', 'Alien Film' with 'Creature Film' and 'Science Fiction'. Furthermore we can identify subgenres and categorise by the parent genre, for example by replacing 'Parody' with 'Comedy'. we can also identify missspellings and plurals (replacing 'Sport' with 'Sports' and 'Comdedy' with 'Comedy')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9DLL7AZC9nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toReplace = [('Acid western', ['Western']),('Action Comedy', ['Action', 'Comedy']),('Action Thrillers', ['Action', 'Thriller']),('Addiction Drama', ['Drama']),('Adventure Comedy',['Adventure', 'Comedy']),('Alien Film', ['Creature Film', 'Science Fiction']),('Alien invasion', ['Creature Film', 'Science Fiction']),('Animated Musical', ['Animation']),('Animated cartoon', ['Animation']),('Anime', ['Animation']),('Auto racing', ['Sports']),('Backstage Musical', ['Musical']),('Baseball', ['Sports']),('Biker Film', ['Road movie']),('Biographical film', ['Biography']),('Black comedy', ['Comedy']),('Boxing', ['Sports']),('Breakdance', ['Dance']),('Buddy cop', ['Crime']),('Caper story', ['Crime', 'Comedy']),('Chick flick', ['Romance']),('Childhood Drama',['Drama']),('Christian film', ['Religious Film']),('Clay animation', ['Animation']),\n",
        "             ('Combat Films', ['Action']),('Comdedy',['Comedy']),('Comedy Thriller', ['Comedy', 'Thriller']),('Comedy Western', ['Comedy', 'Western']),('Comedy film', ['Comedy']),('Comedy horror', ['Comedy', 'Horror']),('Comedy of Errors', ['Comedy']),('Comedy of manners', ['Comedy']),('Computer Animation', ['Animation']),('Concert film', ['Music']),('Conspiracy fiction', ['Thriller']),('Costume Adventure', ['Adventure']),('Costume Horror', ['Horror']),('Costume drama', ['Drama']),('Courtroom Comedy',['Courtroom', 'Comedy']),('Courtroom Drama',['Courtroom', 'Drama']),('Creature Film', ['Monster']), ('Crime Comedy', ['Crime', 'Comedy']),('Crime Drama', ['Crime', 'Drama']),('Crime Fiction', ['Crime']),('Crime Thriller', ['Crime', 'Thriller']),('Demonic child', ['Horror']),('Detective fiction', ['Detective']),('Docudrama', ['Drama']),('Domestic Comedy', ['Comedy']),('Ealing Comedies', ['Comedy']),('Epic Western', ['Epic', 'Western']),('Erotic Drama', ['Adult', 'Drama']),('Erotic thriller', ['Adult', 'Thriller']),('Erotica', ['Adult']),('Extreme Sports', ['Sports']),('Family Drama', ['Family Film', 'Drama']),\n",
        "             ('Fairy Tale', ['Fantasy']),('Fairy tale', ['Fantasy']),('Fantasy Adventure', ['Fantasy', 'Adventure']),('Fantasy Comedy', ['Fantasy', 'Comedy']),('Fantasy Drama', ['Fantasy', 'Drama']),('Future noir', ['Film noir']),('Gangster Film', ['Crime']),('Gay', ['LGBT']),('Gay Interest', [ 'LGBT']),('Gay Themed', [ 'LGBT']), ('Gay pornography', [ 'LGBT', 'Adult']),('Gender Issues', ['LGBT']),('Glamorized Spy Film', ['Spy']),\n",
        "             ('Gulf War', ['War film']),('Haunted House Film', ['Horror']),('Hardcore pornography', ['Adult']),('Heavenly Comedy', ['Comedy']),('Heist', ['Crime']),('Hip hop movies', ['Music']),('Historical Documentaries', ['History', 'Documentary']),('Historical Epic', ['History']),('Historical drama', ['History']),('Historical Drama', ['History', 'Drama']),('Historical fiction', ['History']),('Homoeroticism', ['Adult', 'LGBT']),('Horror Comedy', ['Horror', 'Comedy']),('Horse racing', ['Sport']),('Humour', ['Comedy']),('Hybrid Western', ['Western']),('Indian Western', ['Western']),('Inspirational Drama', ['Drama']),('Instrumental Music', ['Music']),('Interpersonal Relationships', ['Drama']),('Jukebox musical', ['Musical']),('Legal drama', ['Courtroom']),('Marriage Drama', ['Drama']),('Master Criminal Films', ['Crime']),('Media Satire', ['Comedy']),\n",
        "             ('Melodrama', ['Drama']),('Mockumentary', ['Comedy']),('Monster movie', ['Monster']),('Movies About Gladiators', ['History', 'Action']),('Musical Drama', ['Musical', 'Drama']),('Musical comedy', ['Musical', 'Comedy']), ('Mythological Fantasy',['Fantasy']),('Natural disaster', ['Disaster']), ('Natural horror films', ['Horror']),('Ninja movie', ['Martial Arts Film']),('Operetta', ['Musical']),('Outlaw', ['Crime']),('Outlaw biker film', ['Crime', 'Road movie']),('Parody', ['Comedy']),('Period Horror', ['Period', 'Horror']),('Period piece', ['Period']),('Political cinema', ['Politics']),('Political drama', ['Politics', 'Drama']),('Political satire', ['Politics', 'Comedy']),('Political thriller', ['Politics', 'Thriller']),('Pornographic movie', ['Adult']),('Pornography', ['Adult']),('Prison', ['Crime']),('Prison escape', ['Crime']),('Prison film', ['Crime']),('Psychological horror', ['Horror']),('Psychological thriller', ['Thriller']),\n",
        "             ('Punk rock', ['Music']),('Race movie', ['Sports']),('Revisionist Fairy Tale', ['Fantasy']),('Revisionist Western', ['Western']),('Rockumentary', ['Documentary', 'Music']),('Romance Film', ['Romance']),('Romantic Film', ['Romance']),('Romantic comedy', ['Romance', 'Comedy']),('Romantic drama', ['Romance', 'Drama']),('Romantic fantasy', ['Romance', 'Fantasy']),('Samurai cinema', ['Martial Arts Film']),('Satire', ['Comedy']),('Sci Fi Pictures original films', ['Science Fiction']),('Science fiction Western', ['Science Fiction', 'Western']),('Screwball comedy', ['Comedy']),('Sex comedy', ['Comedy']),('Slapstick', ['Comedy']),('Slasher', ['Horror']),('Softcore Porn', ['Adult']),('Space opera', ['Science Fiction', 'Musical']),('Space western', ['Science Fiction', 'Western']),('Spaghetti Western', ['Western']),('Spaghetti western', ['Western']),('Splatter film', ['Horror']),('Sport', [ 'Sports']),('Stop motion', ['Animation']),('Supermarionation', ['Animation']),('Swashbuckler films', ['Adventure']),\n",
        "             ('Therimin music', ['Music']), ('Time travel', ['Science Fiction']),('Tragicomedy', ['Comedy', 'Tragedy']),('Vampire movies', ['Horror']),('War effort', ['War film']),('Werewolf fiction', ['Monster']),('Whodunit', ['Detective']),('Women in prison films', ['Prison']),('World History', ['History']),('Workplace Comedy', ['Comedy']),('Zombie Film', ['Monster'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7x1YHijC9nV",
        "colab_type": "text"
      },
      "source": [
        "The following two functions can remove and replace genres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFk4XciHC9nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class wordRemover():\n",
        "    def __init__(self, word):\n",
        "        self.word = word\n",
        "        \n",
        "    def removeWord(self, listOfWords):\n",
        "        if self.word in listOfWords:\n",
        "            index = listOfWords.index(self.word)\n",
        "            del listOfWords[index]\n",
        "        return listOfWords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P0107kLC9nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class wordReplacer():\n",
        "    def __init__(self, word, replacements):\n",
        "        self.word = word\n",
        "        self.replacements = replacements\n",
        "        \n",
        "    def replaceWord(self, listOfWords):\n",
        "        if self.word in listOfWords:\n",
        "            index = listOfWords.index(self.word)\n",
        "            del listOfWords[index]\n",
        "            for replacement in self.replacements:\n",
        "                if replacement not in listOfWords:\n",
        "                    listOfWords.append(replacement)\n",
        "        return listOfWords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_La4orgC9ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word in toDelete:\n",
        "    result.genres = result.genres.apply(wordRemover(word).removeWord)\n",
        "\n",
        "for word, replacements in toReplace:\n",
        "    result.genres = result.genres.apply(wordReplacer(word, replacements).replaceWord)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cObnDwyTC9np",
        "colab_type": "text"
      },
      "source": [
        "We now binarize the data and find a total of 40 different genres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEV0ZoXzC9nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "binarizer = MultiLabelBinarizer()\n",
        "y = binarizer.fit_transform(result.genres)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eNWBL0c7C9nw",
        "colab_type": "code",
        "outputId": "7d2ba2d8-bf42-4b28-95b5-ca4cf8c9e54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "binarizer.classes_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Action', 'Adult', 'Adventure', 'Animation', 'Biography', 'Comedy',\n",
              "       'Courtroom', 'Crime', 'Dance', 'Detective', 'Disaster',\n",
              "       'Documentary', 'Drama', 'Dystopia', 'Epic', 'Family Film',\n",
              "       'Fantasy', 'Film noir', 'History', 'Horror', 'LGBT',\n",
              "       'Martial Arts Film', 'Monster', 'Music', 'Musical', 'Mystery',\n",
              "       'Period', 'Politics', 'Prison', 'Religious Film', 'Road movie',\n",
              "       'Romance', 'Science Fiction', 'Silent film', 'Sports', 'Spy',\n",
              "       'Supernatural', 'Suspense', 'Teen', 'Thriller', 'Tragedy',\n",
              "       'War film', 'Western'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH6sjv9iC9n0",
        "colab_type": "text"
      },
      "source": [
        "The genre data is stored as ones and zeros e.g."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ80wgm0C9n1",
        "colab_type": "code",
        "outputId": "8d6b2ee1-791d-4943-9f38-c2650371faab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "y[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZisqHyy-bqs3",
        "colab_type": "code",
        "outputId": "f0fc6b0f-df0d-47e5-e446-84314aca5947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24774, 43)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6kZj3T3C9n4",
        "colab_type": "text"
      },
      "source": [
        "But we can easily see what genres this vector corresponds to by doing an inverse transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx0xCCzFC9n5",
        "colab_type": "code",
        "outputId": "e9656904-fd7d-40ee-cf55-0e54f3c991c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "binarizer.inverse_transform(y[:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Adult', 'Thriller'), ('Adventure', 'Family Film', 'Fantasy')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At99isqTC9oB",
        "colab_type": "text"
      },
      "source": [
        "Note that there is some leakage from the training set to the test set by binarizing the data before the test train split. In practice this has no affect since we canot fit genres which aren't in the training set and so we will just predict false on all such genres not present in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kv9rb0LC9oD",
        "colab_type": "text"
      },
      "source": [
        "Let's split the data set into training and test sets. We won't look at the test set again till the very end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kz6wFkAbc07",
        "colab_type": "code",
        "outputId": "8d18f675-ff36-4d3b-b15e-6111c5157f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "result.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 24774 entries, 9363483 to 12476867\n",
            "Data columns (total 6 columns):\n",
            "name         24774 non-null object\n",
            "date         24194 non-null object\n",
            "languages    24774 non-null object\n",
            "countries    24774 non-null object\n",
            "genres       24774 non-null object\n",
            "synopsis     24774 non-null object\n",
            "dtypes: object(6)\n",
            "memory usage: 1.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-7SjcRjb0J-",
        "colab_type": "code",
        "outputId": "94d52e79-b363-4eee-848e-c1083f276bfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "result.synopsis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9363483     A series of murders of rich young women throug...\n",
              "18998739    Every hundred years, the evil Morgana  returns...\n",
              "6631279     Adam, a San Francisco-based artist who works a...\n",
              "171005      {{Plot|dateAct 1Act 2Act 3Act 4Act 5 Finally n...\n",
              "11250635     The story starts as one of the robots flies i...\n",
              "                                  ...                        \n",
              "1918494     Havoc is wrought on the inhabitants of a small...\n",
              "23851782    {{plot}} The film opens with a Great Western e...\n",
              "35228177    Two former National Oceanic Atmospheric Admini...\n",
              "34980460    {{No plot}} This film follows 12 years in the ...\n",
              "12476867    The movie is about a teenage girl who loves ho...\n",
              "Name: synopsis, Length: 24774, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79KAMHLSC9oF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(result[\"synopsis\"],y,\n",
        "                                                    test_size=0.2, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To_X2VcvC9oO",
        "colab_type": "text"
      },
      "source": [
        "And now let's look at the distribution of genres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiMjsG_JC9oR",
        "colab_type": "code",
        "outputId": "9436ca71-8d94-4a00-fb3e-d6b38e1eae8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "labelCounts = y_train.sum(axis=0)\n",
        "n, bins, patches = plt.hist(labelCounts, bins=np.logspace(1, 4, 9))\n",
        "plt.semilogx()\n",
        "plt.title(\"Distribution of genre counts\")\n",
        "plt.xlabel(\"Number of movies with given genre\")\n",
        "plt.ylabel(\"Number of genres\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Number of genres')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEaCAYAAAAWvzywAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVYwTv5lZxfx/mCEoEJufSbMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syDVWkOYC9oY",
        "colab_type": "text"
      },
      "source": [
        "We see there are a handful of genres that appear in the training set less than a hundred times and some that appear many thousands of times with most appearing several hundred times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr-vz1l0C9oa",
        "colab_type": "text"
      },
      "source": [
        "## 2. Feature analysis and wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K_qmKhzC9oc",
        "colab_type": "code",
        "outputId": "55c91163-b991-446f-c0d7-b6251ed87976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "genreDF = pd.DataFrame(y_train, columns = binarizer.classes_)\n",
        "genreDF.Comedy.sum()/genreDF.Comedy.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3571320450073162"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfz0KD_UaqGv",
        "colab_type": "code",
        "outputId": "de9e1681-ad11-427b-dff9-3db2e7b95ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "genreDF = pd.DataFrame(y_train, columns = binarizer.classes_)\n",
        "genreDF.Action.sum()/genreDF.Action.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.148594782784197"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB2smfkVazQR",
        "colab_type": "code",
        "outputId": "9de7b751-03b2-4c99-f9ee-68f7af744975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "genreDF = pd.DataFrame(y_train, columns = binarizer.classes_)\n",
        "genreDF.Adult.sum()/genreDF.Adult.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.013017811191281094"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIk3AvTOC9oi",
        "colab_type": "text"
      },
      "source": [
        "So now let's wrangle the text. \n",
        "\n",
        "First, a review of the text shows that some of the data contains tags such as \"{{plot}}\" and \"{{No plot}}\" For Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b98BC1b5bHGg",
        "colab_type": "code",
        "outputId": "e0d4e953-1f75-4c95-9c14-6355f695ff5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Example 1\n",
        "X_train.loc[23851782]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{{plot}} The film opens with a Great Western express speeding out of Box Tunnel on route to Cornwall. The train\\'s passengers include Herbert and Edna, a young couple travelling to Truro to be married, Miss Bourne, a West London spinster visiting evacuated relatives, Tommy Gander, an overenthusiastic Vaudeville-style comedian and entertainer headed for the Pier Pavilion at Newquay to put on a show, Dr Sterling, a locum for a doctor in Redruth, Richard G Winthrop and his cousin Jackie, also heading for Truro, and Teddy Deakin. Just as they are passing Teignmouth, the communication cord is pulled and the train stops - only for the guard and passengers to find that Gander has lost his hat and is running back to retrieve it. Ignorant of the delay this has caused, he returns to the train and comes across Jackie Winthrop in her compartment. Gander tries to make conversation with her, but Teddy has his eye on Jackie and is quick to try and send him packing - at one point he insinuates that Gander is in a first class carriage with a third class ticket, whereupon Gander jokingly retorts by saying he has a platform ticket. Richard has no time for either of them, so they both annoy him by pacing back and forth outside his compartment. Gander makes silly faces until Richard loses patience and shuts the blinds over their windows. The train arrives at Fal Vale Junction, Cornwall. Teddy and Gander are quick to help Jackie with her luggage. Gander offers to share his compartment, but Teddy points out that they are travelling first class, and that Richard dislikes the comedian. Instead they set about helping Miss Bourne, who initially mistakes a carriage window for a door, with her luggage, including her pet parrot, Polly. Just before the train leaves, Gander realises he has forgotten about his basket containing props and costumes. He is annoyed when the guard tells him he had thrown it out of the van. Once the train has left, the passengers meet Fal Vale\\'s stationmaster Saul Hodgkin. He tells them that the last Truro-bound train has gone, and that there won\\'t be another until morning; he is just about to lock up for the night. Upon Richard\\'s irate prompting, and knowing that he has to rehearse at Newquay the next morning, Gander tries to charter a special, but Saul refuses to make arrangements. As he is preparing his bicycle, rain starts to fall, and the passengers make for the station waiting room, taking out their frustrations on Gander for his lost hat. Saul tries to make it clear that \"You can\\'t stay here\", but the passengers insist on staying until transport can be arranged. Eventually Saul telephones for a bus, but for some reason is unable to requisition one. He suggests that they walk to the local village, but the passengers object upon hearing that it is four miles away. In the meantime, Gander has rescued his basket from the rain, and borrows the ticket office as a changing room. In spite of the passengers\\' firm decision to stay put, Saul cannot bring himself to leave them alone, and neither does he wish to stay with them - his reason being that the station is haunted...... In 1897, a branch line was run from Fal Vale Junction to an old port, crossing the river on a swing bridge at the other end of a tunnel close to the station. The swing bridge, worked by a wheel on the platform, was kept open for china clay boats, but was closed whenever trains had to cross it. One day, some locals chartered a special train to take them home, and the then stationmaster, Ted Holmes, was kept on late night duty to close the bridge for it. At eleven o\\'clock, he went to close the bridge, but he had a heart attack before he could finish doing it. He tried to get back to his office and warn Truro about the bridge, but his heart failed and he collapsed with his lamp still burning in his hand. With Holmes dead and the bridge still open, there was no way of preventing a crash. Although something warned the train driver, Ben Isaacs, of the danger, he was unable to stop and the train plunged through the open bridge into the river. The branch line was supposedly closed afterwards, and the bridge has always remained in the open position. Ever since that day, Saul explains, there have been occasions when a train is heard desperately trying to pull up near the station. It never arrives anywhere, and neither does it start from Truro, and it is said to kill anyone who looks upon it. \"If it be a natural thing,\" he asks, \"where do it come from...where do it go?\" With that, Saul reluctantly leaves the passengers, warning them not to look if they hear a train that night. Miss Bourne is still shaken after hearing his story, but Richard sceptically passes it off as nonsense. Gander has been listening in on the story too, and makes a great fuss of it; in order to take his mind off things, Richard starts a game of chess with Dr Sterling. Gander tries to liven things up by singing \"The Seaside Band\", but this ends prematurely when Richard loses his temper and throws his gramophone out onto the track. In a surprisingly calm act of retaliation, Gander picks up the chess set and throws it into the fireplace. After another few moments, Miss Bourne hears something in the station buffet. Richard goes to investigate, followed by Gander who pretends that someone is trying to murder him, but it turns out there is nothing to worry about. Gander then notices that Miss Bourne has some tea with her, and they decide to make some up for refreshment. Teddy sends Gander to fetch some water while he and Jackie prepare to make the tea, but the only source turns out to be a water crane on the platform. In order to stay dry, Gander improvises a raincoat from a tablecloth and a sheet of tarpaulin, but while obtaining his supply of water he finds the old bridge wheel. Curious as to what might happen, he tries to turn it, but the wheel is chained and padlocked, and he can barely move it. He gives up and takes the water into the buffet, where he makes mention of the wheel to Teddy and Jackie before \"tea-urning the gas on\" in a rather flashy fashion. Again he tries to start conversation with Jackie, but Teddy interferes again and sends him back into the waiting room, where he tries in vain to entertain the other passengers with ghost stories. Teddy and Jackie soon bring the tea through to the waiting room, and the passengers share out what little food they have to make a meal of it. During their midnight meal, Gander acts as if Ted Holmes\\' ghost is lying in the doorway to the branch line platform, repeatedly stumbling as if the ghost had tripped him up. In the end he moves the \"ghost\" out of harm\\'s way and offers to provide a dessert from a chocolate machine outside. When he returns, however, he finds to his disappointment that he has bought several boxes of matches. As he is telling a story of an accompanying passenger smoking a cigarette until it burned through his lip , they hear footsteps outside. Richard opens the door to the branch line platform, and a seriously ill Saul Hodgkin collapses into the room. Gander rushes outside with his lamp and raincoat to fill a glass with water from the water crane while Richard, Teddy and Dr Sterling carry Saul into the ticket office. By the time Gander arrives back, Dr Sterling pronounces Saul dead. When Edna hears about it, she scared to stay at the station with a corpse. Edna persuades her reluctant fiancé, Herbert, that they would be better off trying to get back to her mother. Teddy tries to call the police, but the line appears to be down. Miss Bourne is in a dreadful state after she fainted when Saul collapsed into the room, so Gander borrows a bottle of brandy from Dr Sterling to soothe her nerves. Although a strict temperance teetotaler, Miss Bourne drinks the whole lot and becomes noticeably drunk. Teddy, Jackie and Gander bring her through to the buffet to sleep it off, during which Gander tries and fails comically at a trick he had seen at the Hippodrome where all the crockery stays on the table when he pulls the rug off. Shortly after, Herbert and Edna burst into the waiting room with only half their luggage. A knock is heard, and they open the door to reveal a terrified young woman in black. The stranger pleads for help, saying that someone is coming for her, but there is something she has to see. The passengers are confused, particularly when the young woman acts as if they know what she is talking about - until Teddy sees a car coming down the road. As they watch, the car spins off the road and crashes into a tree, so Teddy, accompanied by Gander and Dr Sterling, go to see what has happened. The driver of the car is unhurt, but his car is badly damaged. It turns out that he had skidded on Herbert and Edna\\'s luggage, including a fender donated them by the owner of a furniture shop. They return to the waiting room with the battered luggage and the driver of the car, who introduces himself as Price and explains that he has come in search of his sister Julia. He adds that she suffers from delusions, and is normally kept under observation. Julia overhears, and emerges from the buffet protesting that he is lying. Price further explains that she once thought she had seen the ghost train, and this was such a shock to her that has retained a fascination for it ever since, and experiences compulsions to try and see it again. He is curious, however, as to how they heard about the ghost train; the passengers reply that Saul Hodgkin had told them, but is lying dead in the ticket office. Price goes to take a look, but Saul\\'s body has mysteriously vanished, and his desk was just the way he had left it earlier. When they explain to Price what had happened, Julia insinuates that it was actually Ted Holmes. Dr Sterling suggests that Julia remains at the station until she realises that the ghost train doesn\\'t exist. Price reluctantly concedes, but insists before he leaves that Julia comes back with him as soon as he can find a car. Some time after he leaves, a signal bell is heard to ring in the ticket office, followed by the shrieking whistle of an approaching train. Teddy and Richard try to open the doors and get a look at the train, but the doors won\\'t open. As it thunders through the station, Julia smashes a window to get a look at the train, but faints the moment she sees it. Dr Sterling makes her comfortable on one of the waiting room benches and requests for a glass of water. Teddy and Gander, who suspect trouble, take this opportunity to go outside to do some sleuthing. The rain has stopped, but Gander is surprised to find that Saul\\'s lamp has vanished too. Further surprise comes when Teddy finds the bridge has been closed - then they hear singing from the tunnel mouth, and look to see someone wandering towards them. Julia hears it from the waiting room, and claims that Ben Isaacs, the sole survivor of the accident, is coming back just as he had after the accident - out of his mind and singing \"Rock of Ages\". Teddy knows better, however, and shoots at the \"ghost\", causing it to flee back into the tunnel. He and Gander run after it, but Teddy spots a sheet of cloth with drops of blood on it, and heads back to the waiting room. Gander doesn\\'t realise Teddy\\'s distraction until he is some way into the tunnel. Price has managed to requisition a bus, but is perplexed to hear from Richard that \"some idiot\\'s been fooling around with a gun outside\". At that very same moment, Teddy re-enters the room and holds everyone at gunpoint, locking the doors as he does so. He shows them the bloodstained cloth and begins to explain about the hoax behind the ghost train; someone has taken advantage of the accident and a local superstition to make their job easier, except that it didn\\'t work on him and his fellow passengers. This ghost train, he adds, \"happens to be as real as the Plymouth Express\". But before he can elaborate on this, Jackie points out that Gander was the reason for them being here in the first place. Teddy is taken off guard by this, allowing Richard to punch him hard in the jaw and knock him out. They carry him to the bus with their luggage, and are just about to start away when Gander arrives in time to catch it. He notices Teddy lying unconscious next to him and tries to bring him round. When at last Teddy comes to, he is furious with Richard for what he had done, for now there will be no-one to intercept the train on its return journey. Julia insists that \"the ghost train never comes back\", but Teddy counters that it is more obliging in that makes a return journey. Gander remarks that if it is a ghost train, it won\\'t matter if the bridge is open - and points out that that was what he had done a few moments back. Dr Sterling suddenly moves towards the front of the bus at this point and orders the driver to stop, while Julia and her brother hold everyone at gunpoint. He tells the driver that the bridge is open, and orders him to turn back so that they can warn the train. Meanwhile, guns are being loaded aboard the \"ghost train\" from a nearby beach. As it turns out, Saul Hodgkin is very much alive and in the thick of the business. He flags the train off and climbs aboard as they start away with their illegal cargo. On the bus, Teddy explains to Richard that the \"ghost train\" is really a gunrunners\\' train being used by Fifth Columnists sympathetic to the Nazi movement, with Price as their leader. In the distance, Julia can see the train on the last curve before the bridge. Price and Sterling order the driver to stop, and Price heads down the embankment with Julia and the driver to try and stop the train, but it pays little heed to them as it hurtles towards the bridge. Just as Sterling is trying to retrieve Teddy\\'s gun from Richard, Gander sounds a buzzer in the driver\\'s cab, startling the doctor and enabling Teddy to knock him unconscious. Taking Sterling\\'s gun with them, the passengers make their escape. At the same time, the driver of the ghost train realises too late that the bridge is open, and applies his brakes. But there is nothing he can do to stop in time, and the train takes a nose-dive from the bridge and crashes into the river. Afterwards, Teddy discreetly explains to Gander that, \"confidentially\", he isn\\'t whom he makes himself out to be, indicating that he may officially have been sent to investigate the case for British Intelligence. Richard admits that he has been rather foolish, and apologises to both Teddy and Gander. Miss Bourne then staggers out of the buffet with a terrible headache. Thankful that, as far as she is concerned, \"nothing exciting has happened\", she makes for the special train they have ordered while Teddy and Gander look on in amusement.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_578SR0NC9ol",
        "colab_type": "code",
        "outputId": "6ea295ab-2fed-4b8b-d00b-2456c2fea67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Example 2\n",
        "X_train.loc[34980460]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{{No plot}} This film follows 12 years in the lives of 3 Irish traveller familys  and their bitter feuds and fights. The film explores the reasons why they hold these fights and explores the in-depth secret lives of the familys, which is barely known to outsiders of the travelling community. A gripping tale of passion and respect and blood bonds that will never end.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue4B_HsBC9os",
        "colab_type": "text"
      },
      "source": [
        "In fact these tags are contained in almost 8% of the training set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me0KlLsQC9ot",
        "colab_type": "code",
        "outputId": "99d25be2-cd52-46c5-d284-ddf0d587ebe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#for {{Plot}}\n",
        "X_train.str.contains(\"{{\\w*}}\", case=False).mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04414955345880216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSilGfh8f9Tv",
        "colab_type": "code",
        "outputId": "1a0328f0-8c6f-49d4-be08-77d5a7daa976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#for  {{No Plot}}\n",
        "X_train.str.contains(\"{{\\w* \\w*}}\", case=False).mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.043190877440839597"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Nd_ntGC9o0",
        "colab_type": "text"
      },
      "source": [
        "Now we create a data wrangling pripeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNgIuOvBC9o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deleteSynopsisTags_1(X):\n",
        "  return X.str.replace(\"\\s*{{\\w*}}\\s*\", \"\", case=False)\n",
        "    \n",
        "def deleteSynopsisTags_2(X):\n",
        "  return X.str.replace(\"\\s*{{\\w* \\w*}}\\s*\", \"\", case=False)\n",
        "\n",
        "deleteSynopsisTagsTransformer_1 = FunctionTransformer(deleteSynopsisTags_1, validate=False)\n",
        "deleteSynopsisTagsTransformer_2 = FunctionTransformer(deleteSynopsisTags_2, validate=False)\n",
        "\n",
        "X_wrangle_1 = deleteSynopsisTagsTransformer_1.fit_transform(X_train)\n",
        "X_wrangle_2 = deleteSynopsisTagsTransformer_2.fit_transform(X_wrangle_1)\n",
        "\n",
        "X_test_wrangle_1 = deleteSynopsisTagsTransformer_1.transform(X_test)\n",
        "X_test_wrangle_2 = deleteSynopsisTagsTransformer_2.transform(X_test_wrangle_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_fFkmGaC9o7",
        "colab_type": "text"
      },
      "source": [
        "And we see that these tags are now gone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-ivKB7-C9o8",
        "colab_type": "code",
        "outputId": "42a5e8bc-455a-41ce-9ffe-54203160943f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X_wrangle_2.loc[23851782]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The film opens with a Great Western express speeding out of Box Tunnel on route to Cornwall. The train\\'s passengers include Herbert and Edna, a young couple travelling to Truro to be married, Miss Bourne, a West London spinster visiting evacuated relatives, Tommy Gander, an overenthusiastic Vaudeville-style comedian and entertainer headed for the Pier Pavilion at Newquay to put on a show, Dr Sterling, a locum for a doctor in Redruth, Richard G Winthrop and his cousin Jackie, also heading for Truro, and Teddy Deakin. Just as they are passing Teignmouth, the communication cord is pulled and the train stops - only for the guard and passengers to find that Gander has lost his hat and is running back to retrieve it. Ignorant of the delay this has caused, he returns to the train and comes across Jackie Winthrop in her compartment. Gander tries to make conversation with her, but Teddy has his eye on Jackie and is quick to try and send him packing - at one point he insinuates that Gander is in a first class carriage with a third class ticket, whereupon Gander jokingly retorts by saying he has a platform ticket. Richard has no time for either of them, so they both annoy him by pacing back and forth outside his compartment. Gander makes silly faces until Richard loses patience and shuts the blinds over their windows. The train arrives at Fal Vale Junction, Cornwall. Teddy and Gander are quick to help Jackie with her luggage. Gander offers to share his compartment, but Teddy points out that they are travelling first class, and that Richard dislikes the comedian. Instead they set about helping Miss Bourne, who initially mistakes a carriage window for a door, with her luggage, including her pet parrot, Polly. Just before the train leaves, Gander realises he has forgotten about his basket containing props and costumes. He is annoyed when the guard tells him he had thrown it out of the van. Once the train has left, the passengers meet Fal Vale\\'s stationmaster Saul Hodgkin. He tells them that the last Truro-bound train has gone, and that there won\\'t be another until morning; he is just about to lock up for the night. Upon Richard\\'s irate prompting, and knowing that he has to rehearse at Newquay the next morning, Gander tries to charter a special, but Saul refuses to make arrangements. As he is preparing his bicycle, rain starts to fall, and the passengers make for the station waiting room, taking out their frustrations on Gander for his lost hat. Saul tries to make it clear that \"You can\\'t stay here\", but the passengers insist on staying until transport can be arranged. Eventually Saul telephones for a bus, but for some reason is unable to requisition one. He suggests that they walk to the local village, but the passengers object upon hearing that it is four miles away. In the meantime, Gander has rescued his basket from the rain, and borrows the ticket office as a changing room. In spite of the passengers\\' firm decision to stay put, Saul cannot bring himself to leave them alone, and neither does he wish to stay with them - his reason being that the station is haunted...... In 1897, a branch line was run from Fal Vale Junction to an old port, crossing the river on a swing bridge at the other end of a tunnel close to the station. The swing bridge, worked by a wheel on the platform, was kept open for china clay boats, but was closed whenever trains had to cross it. One day, some locals chartered a special train to take them home, and the then stationmaster, Ted Holmes, was kept on late night duty to close the bridge for it. At eleven o\\'clock, he went to close the bridge, but he had a heart attack before he could finish doing it. He tried to get back to his office and warn Truro about the bridge, but his heart failed and he collapsed with his lamp still burning in his hand. With Holmes dead and the bridge still open, there was no way of preventing a crash. Although something warned the train driver, Ben Isaacs, of the danger, he was unable to stop and the train plunged through the open bridge into the river. The branch line was supposedly closed afterwards, and the bridge has always remained in the open position. Ever since that day, Saul explains, there have been occasions when a train is heard desperately trying to pull up near the station. It never arrives anywhere, and neither does it start from Truro, and it is said to kill anyone who looks upon it. \"If it be a natural thing,\" he asks, \"where do it come from...where do it go?\" With that, Saul reluctantly leaves the passengers, warning them not to look if they hear a train that night. Miss Bourne is still shaken after hearing his story, but Richard sceptically passes it off as nonsense. Gander has been listening in on the story too, and makes a great fuss of it; in order to take his mind off things, Richard starts a game of chess with Dr Sterling. Gander tries to liven things up by singing \"The Seaside Band\", but this ends prematurely when Richard loses his temper and throws his gramophone out onto the track. In a surprisingly calm act of retaliation, Gander picks up the chess set and throws it into the fireplace. After another few moments, Miss Bourne hears something in the station buffet. Richard goes to investigate, followed by Gander who pretends that someone is trying to murder him, but it turns out there is nothing to worry about. Gander then notices that Miss Bourne has some tea with her, and they decide to make some up for refreshment. Teddy sends Gander to fetch some water while he and Jackie prepare to make the tea, but the only source turns out to be a water crane on the platform. In order to stay dry, Gander improvises a raincoat from a tablecloth and a sheet of tarpaulin, but while obtaining his supply of water he finds the old bridge wheel. Curious as to what might happen, he tries to turn it, but the wheel is chained and padlocked, and he can barely move it. He gives up and takes the water into the buffet, where he makes mention of the wheel to Teddy and Jackie before \"tea-urning the gas on\" in a rather flashy fashion. Again he tries to start conversation with Jackie, but Teddy interferes again and sends him back into the waiting room, where he tries in vain to entertain the other passengers with ghost stories. Teddy and Jackie soon bring the tea through to the waiting room, and the passengers share out what little food they have to make a meal of it. During their midnight meal, Gander acts as if Ted Holmes\\' ghost is lying in the doorway to the branch line platform, repeatedly stumbling as if the ghost had tripped him up. In the end he moves the \"ghost\" out of harm\\'s way and offers to provide a dessert from a chocolate machine outside. When he returns, however, he finds to his disappointment that he has bought several boxes of matches. As he is telling a story of an accompanying passenger smoking a cigarette until it burned through his lip , they hear footsteps outside. Richard opens the door to the branch line platform, and a seriously ill Saul Hodgkin collapses into the room. Gander rushes outside with his lamp and raincoat to fill a glass with water from the water crane while Richard, Teddy and Dr Sterling carry Saul into the ticket office. By the time Gander arrives back, Dr Sterling pronounces Saul dead. When Edna hears about it, she scared to stay at the station with a corpse. Edna persuades her reluctant fiancé, Herbert, that they would be better off trying to get back to her mother. Teddy tries to call the police, but the line appears to be down. Miss Bourne is in a dreadful state after she fainted when Saul collapsed into the room, so Gander borrows a bottle of brandy from Dr Sterling to soothe her nerves. Although a strict temperance teetotaler, Miss Bourne drinks the whole lot and becomes noticeably drunk. Teddy, Jackie and Gander bring her through to the buffet to sleep it off, during which Gander tries and fails comically at a trick he had seen at the Hippodrome where all the crockery stays on the table when he pulls the rug off. Shortly after, Herbert and Edna burst into the waiting room with only half their luggage. A knock is heard, and they open the door to reveal a terrified young woman in black. The stranger pleads for help, saying that someone is coming for her, but there is something she has to see. The passengers are confused, particularly when the young woman acts as if they know what she is talking about - until Teddy sees a car coming down the road. As they watch, the car spins off the road and crashes into a tree, so Teddy, accompanied by Gander and Dr Sterling, go to see what has happened. The driver of the car is unhurt, but his car is badly damaged. It turns out that he had skidded on Herbert and Edna\\'s luggage, including a fender donated them by the owner of a furniture shop. They return to the waiting room with the battered luggage and the driver of the car, who introduces himself as Price and explains that he has come in search of his sister Julia. He adds that she suffers from delusions, and is normally kept under observation. Julia overhears, and emerges from the buffet protesting that he is lying. Price further explains that she once thought she had seen the ghost train, and this was such a shock to her that has retained a fascination for it ever since, and experiences compulsions to try and see it again. He is curious, however, as to how they heard about the ghost train; the passengers reply that Saul Hodgkin had told them, but is lying dead in the ticket office. Price goes to take a look, but Saul\\'s body has mysteriously vanished, and his desk was just the way he had left it earlier. When they explain to Price what had happened, Julia insinuates that it was actually Ted Holmes. Dr Sterling suggests that Julia remains at the station until she realises that the ghost train doesn\\'t exist. Price reluctantly concedes, but insists before he leaves that Julia comes back with him as soon as he can find a car. Some time after he leaves, a signal bell is heard to ring in the ticket office, followed by the shrieking whistle of an approaching train. Teddy and Richard try to open the doors and get a look at the train, but the doors won\\'t open. As it thunders through the station, Julia smashes a window to get a look at the train, but faints the moment she sees it. Dr Sterling makes her comfortable on one of the waiting room benches and requests for a glass of water. Teddy and Gander, who suspect trouble, take this opportunity to go outside to do some sleuthing. The rain has stopped, but Gander is surprised to find that Saul\\'s lamp has vanished too. Further surprise comes when Teddy finds the bridge has been closed - then they hear singing from the tunnel mouth, and look to see someone wandering towards them. Julia hears it from the waiting room, and claims that Ben Isaacs, the sole survivor of the accident, is coming back just as he had after the accident - out of his mind and singing \"Rock of Ages\". Teddy knows better, however, and shoots at the \"ghost\", causing it to flee back into the tunnel. He and Gander run after it, but Teddy spots a sheet of cloth with drops of blood on it, and heads back to the waiting room. Gander doesn\\'t realise Teddy\\'s distraction until he is some way into the tunnel. Price has managed to requisition a bus, but is perplexed to hear from Richard that \"some idiot\\'s been fooling around with a gun outside\". At that very same moment, Teddy re-enters the room and holds everyone at gunpoint, locking the doors as he does so. He shows them the bloodstained cloth and begins to explain about the hoax behind the ghost train; someone has taken advantage of the accident and a local superstition to make their job easier, except that it didn\\'t work on him and his fellow passengers. This ghost train, he adds, \"happens to be as real as the Plymouth Express\". But before he can elaborate on this, Jackie points out that Gander was the reason for them being here in the first place. Teddy is taken off guard by this, allowing Richard to punch him hard in the jaw and knock him out. They carry him to the bus with their luggage, and are just about to start away when Gander arrives in time to catch it. He notices Teddy lying unconscious next to him and tries to bring him round. When at last Teddy comes to, he is furious with Richard for what he had done, for now there will be no-one to intercept the train on its return journey. Julia insists that \"the ghost train never comes back\", but Teddy counters that it is more obliging in that makes a return journey. Gander remarks that if it is a ghost train, it won\\'t matter if the bridge is open - and points out that that was what he had done a few moments back. Dr Sterling suddenly moves towards the front of the bus at this point and orders the driver to stop, while Julia and her brother hold everyone at gunpoint. He tells the driver that the bridge is open, and orders him to turn back so that they can warn the train. Meanwhile, guns are being loaded aboard the \"ghost train\" from a nearby beach. As it turns out, Saul Hodgkin is very much alive and in the thick of the business. He flags the train off and climbs aboard as they start away with their illegal cargo. On the bus, Teddy explains to Richard that the \"ghost train\" is really a gunrunners\\' train being used by Fifth Columnists sympathetic to the Nazi movement, with Price as their leader. In the distance, Julia can see the train on the last curve before the bridge. Price and Sterling order the driver to stop, and Price heads down the embankment with Julia and the driver to try and stop the train, but it pays little heed to them as it hurtles towards the bridge. Just as Sterling is trying to retrieve Teddy\\'s gun from Richard, Gander sounds a buzzer in the driver\\'s cab, startling the doctor and enabling Teddy to knock him unconscious. Taking Sterling\\'s gun with them, the passengers make their escape. At the same time, the driver of the ghost train realises too late that the bridge is open, and applies his brakes. But there is nothing he can do to stop in time, and the train takes a nose-dive from the bridge and crashes into the river. Afterwards, Teddy discreetly explains to Gander that, \"confidentially\", he isn\\'t whom he makes himself out to be, indicating that he may officially have been sent to investigate the case for British Intelligence. Richard admits that he has been rather foolish, and apologises to both Teddy and Gander. Miss Bourne then staggers out of the buffet with a terrible headache. Thankful that, as far as she is concerned, \"nothing exciting has happened\", she makes for the special train they have ordered while Teddy and Gander look on in amusement.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMVML0S1ebI3",
        "colab_type": "code",
        "outputId": "ec8ee70a-07d8-4b7a-8d78-8ca09cdaf19d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X_wrangle_2.loc[34980460]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This film follows 12 years in the lives of 3 Irish traveller familys  and their bitter feuds and fights. The film explores the reasons why they hold these fights and explores the in-depth secret lives of the familys, which is barely known to outsiders of the travelling community. A gripping tale of passion and respect and blood bonds that will never end.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dina3ziC9pA",
        "colab_type": "text"
      },
      "source": [
        "So now I want to start making fits to the Comedy genre data, identifying the most important features and so finding possible sources of error. \n",
        "\n",
        "First though I need to choose an appropraite score to measure the fit quality. I will choose the micro f1 score which balanaces precision (reducing false negatives) and accuracy (reducing false positives). The is implemented here for a single label (Later I will extend this to multilabel)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1n0RZH3C9pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def customF1(hat, actual, **kwargs):\n",
        "    accuracy = ((actual*hat).sum())/actual.sum()\n",
        "    precision = ((actual*hat).sum())/hat.sum()\n",
        "    if accuracy==0 or precision==0:\n",
        "        f1= 0\n",
        "    else:\n",
        "        f1= 2.* pow(pow(accuracy, -1) + pow(precision, -1), -1)\n",
        "    return f1\n",
        "customF1Scorer = make_scorer(customF1, greater_is_better=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBJv8gMxC9pK",
        "colab_type": "text"
      },
      "source": [
        "So let's identify the most important features and the quality of the fit. The folloiwng code vectorizes the synopsis, and prints out the 200 most important words for determing whether a movie is a comedy using a $\\chi^2$ imformation metric. Next we perform a fit over the most important features and print the resulting cross validation score and training score. By printing both we will identify possible overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwqFKveQC9pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mostImportantFeatures(X, y):\n",
        "    count = CountVectorizer(lowercase=False, strip_accents='unicode', min_df = 3, stop_words='english')\n",
        "    #print the most important features\n",
        "    selector = SelectKBest(chi2, 200)\n",
        "    X_Vec = count.fit_transform(X, y)\n",
        "    X_select = selector.fit_transform(X_Vec, y)\n",
        "    print (np.unique([name for name, val in zip(count.get_feature_names(), selector.get_support()) if val==True]))\n",
        "    #get a fit score based on the most important featrures\n",
        "    MultinomialPipe = Pipeline([\n",
        "                                (\"count\", count),\n",
        "                                (\"selector\", SelectPercentile(chi2)),\n",
        "                                (\"model\", MultinomialNB(alpha = 1e-9, fit_prior=False))\n",
        "                               ])\n",
        "    rs = RandomizedSearchCV(MultinomialPipe, param_distributions={\"selector__percentile\":sp_randint(1, 50)}, \n",
        "                            n_iter=3,\n",
        "                            scoring=customF1Scorer, verbose=0, \n",
        "                            refit=True, \n",
        "                            cv=10\n",
        "                           )\n",
        "    rs.fit(X, y)\n",
        "    hYat = rs.predict(X)\n",
        "    return rs.best_score_ , rs.best_params_, customF1(y, hYat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36iu7pN-C9pP",
        "colab_type": "code",
        "outputId": "997c33ca-edbd-442d-a8ba-68b55c8b27d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "best_score, best_params, custom_F1 = mostImportantFeatures(X_wrangle_2, genreDF.Comedy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Adam' 'Alfalfa' 'Alfie' 'Andy' 'Anne' 'Archie' 'Austin' 'Bean' 'Beverly'\n",
            " 'Big' 'Bond' 'Brad' 'British' 'Buddy' 'Bugs' 'Butch' 'Casey' 'Catherine'\n",
            " 'Charlie' 'Cheech' 'Chester' 'Chip' 'Christine' 'Chuck' 'Chucky' 'Cindy'\n",
            " 'Clouseau' 'Crewe' 'Curly' 'Daffy' 'Darla' 'Dave' 'David' 'Deuce'\n",
            " 'Dexter' 'Dr' 'Duck' 'Dwayne' 'Ed' 'Elmer' 'Elwood' 'Ernest' 'Ernie'\n",
            " 'Evil' 'Fiona' 'Fitz' 'Fred' 'Garfield' 'George' 'German' 'Germans'\n",
            " 'Gromit' 'Hardy' 'Harold' 'Herbie' 'Hollywood' 'Jackie' 'Japanese'\n",
            " 'Jerry' 'Jimmy' 'John' 'Joseph' 'Josh' 'Judy' 'Kevin' 'Larry' 'Loretta'\n",
            " 'Louie' 'Madea' 'Mame' 'Massie' 'Max' 'Miss' 'Mitch' 'Moe' 'Monty' 'Mr'\n",
            " 'Odie' 'Olive' 'Ollie' 'Pee' 'Pink' 'Porky' 'Ralph' 'Roger' 'Rowley'\n",
            " 'Sach' 'Sam' 'Scam' 'Sharpe' 'Shemp' 'Shrek' 'Slip' 'Spanky' 'Spike'\n",
            " 'Stan' 'Stooges' 'TV' 'Tarzan' 'Tiffany' 'Tom' 'Wally' 'Wang' 'War'\n",
            " 'Woody' 'accidentally' 'alive' 'antics' 'attack' 'attacked' 'attacks'\n",
            " 'ball' 'band' 'battle' 'best' 'bet' 'blood' 'body' 'boyfriend' 'boys'\n",
            " 'cartoon' 'cat' 'comedy' 'company' 'competition' 'contest' 'creature'\n",
            " 'dance' 'date' 'dating' 'dead' 'death' 'decide' 'decides' 'died' 'dies'\n",
            " 'dinner' 'dog' 'ends' 'forces' 'friends' 'game' 'gay' 'gets' 'getting'\n",
            " 'girlfriend' 'girls' 'gun' 'human' 'idea' 'information' 'investigation'\n",
            " 'job' 'kids' 'kill' 'killed' 'killer' 'killing' 'kills' 'kiss' 'make'\n",
            " 'man' 'manager' 'marijuana' 'married' 'men' 'military' 'mission' 'money'\n",
            " 'mouse' 'movie' 'murder' 'murdered' 'murders' 'new' 'party' 'play'\n",
            " 'prisoners' 'prom' 'restaurant' 'scheme' 'school' 'sex' 'ship' 'shoots'\n",
            " 'shot' 'soldier' 'soldiers' 'son' 'song' 'store' 'studio' 'survivors'\n",
            " 'village' 'war' 'wedding' 'win' 'women' 'wounded' 'young']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePwi8SufsnMA",
        "colab_type": "code",
        "outputId": "d5b4bc4f-2d75-46ba-b51d-dda932dedba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"Randomized Search best score: {}\".format(best_score))\n",
        "print(\"grid search best param : {}\".format(best_params))\n",
        "print(\"score on training data : {}\".format(custom_F1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Randomized Search best score: 0.6519936616330153\n",
            "grid search best param : {'selector__percentile': 15}\n",
            "score on training data : 0.7566704966168774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTbxElXjC9pW",
        "colab_type": "text"
      },
      "source": [
        "We see that many of the most important features are names. While we might imagine that a few names could hold some predictive power, the use of names seems likely to contribute to the overfitting we observe. Lets remove them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAetPYa2C9pY",
        "colab_type": "code",
        "outputId": "789b1fe2-f8b6-408c-b210-f5eae797e6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "def noCaps(X):\n",
        "    return X.str.replace(r'([A-Z])\\w+', \"\", case=True)\n",
        "\n",
        "noCapsTransform = FunctionTransformer(noCaps, validate=False)\n",
        "\n",
        "X_wrangle_3 = noCapsTransform.fit_transform(X_wrangle_2)\n",
        "X_test_wrangle_3 = noCapsTransform.transform(X_test_wrangle_2)\n",
        "\n",
        "best_score, best_params, custom_F1 = mostImportantFeatures(X_wrangle_3, genreDF.Comedy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['accidentally' 'actor' 'advertising' 'advice' 'aircraft' 'alive' 'antics'\n",
            " 'army' 'attack' 'attacked' 'attacks' 'audience' 'bachelor' 'ball' 'band'\n",
            " 'bar' 'battle' 'best' 'bet' 'big' 'blood' 'body' 'bong' 'bowling' 'boy'\n",
            " 'boyfriend' 'boys' 'brother' 'bumbling' 'business' 'butler' 'buy'\n",
            " 'cartoon' 'cat' 'ceremony' 'cheerleader' 'chef' 'child' 'college'\n",
            " 'comedy' 'comic' 'commander' 'company' 'competition' 'contest' 'cow'\n",
            " 'creature' 'credits' 'crew' 'crime' 'crush' 'dad' 'dance' 'date' 'dating'\n",
            " 'daughter' 'dead' 'death' 'decide' 'decides' 'demon' 'died' 'dies'\n",
            " 'dinner' 'doesn' 'dog' 'drug' 'duo' 'dying' 'eccentric' 'end' 'ends'\n",
            " 'escape' 'evidence' 'executed' 'feelings' 'fish' 'forces' 'friends' 'fun'\n",
            " 'game' 'garbage' 'gay' 'gets' 'getting' 'girlfriend' 'girls' 'golf'\n",
            " 'government' 'group' 'gun' 'guys' 'happy' 'helicopter' 'hockey' 'hotel'\n",
            " 'human' 'idea' 'inept' 'infected' 'information' 'injured' 'investigate'\n",
            " 'investigation' 'job' 'kids' 'kill' 'killed' 'killer' 'killing' 'kills'\n",
            " 'kiss' 'knife' 'likes' 'love' 'make' 'makeover' 'man' 'manager'\n",
            " 'marijuana' 'married' 'men' 'military' 'misadventures' 'mission' 'mom'\n",
            " 'money' 'mouse' 'movie' 'murder' 'murdered' 'murders' 'musical'\n",
            " 'mysterious' 'new' 'officer' 'orders' 'parents' 'party' 'pay' 'penguins'\n",
            " 'penis' 'plan' 'play' 'police' 'power' 'priest' 'prisoner' 'prisoners'\n",
            " 'prize' 'producer' 'prom' 'quits' 'rabbit' 'rape' 'raped' 'remaining'\n",
            " 'restaurant' 'rock' 'salesman' 'scheme' 'school' 'sex' 'ship' 'shoots'\n",
            " 'shop' 'shot' 'singing' 'soldier' 'soldiers' 'son' 'song' 'stabs' 'stage'\n",
            " 'star' 'store' 'studio' 'survivor' 'survivors' 'talent' 'television'\n",
            " 'tortured' 'troops' 'victims' 'village' 'virus' 'visions' 'war' 'wedding'\n",
            " 'white' 'win' 'winning' 'women' 'woo' 'woods' 'wounded' 'wounds' 'years'\n",
            " 'young' 'zoo']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGj73qtPvrx0",
        "colab_type": "code",
        "outputId": "f45223c8-099f-4855-ba43-d161cccdd56b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"Randomized Search best score: {}\".format(best_score))\n",
        "print(\"grid search best param : {}\".format(best_params))\n",
        "print(\"score on training data : {}\".format(custom_F1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Randomized Search best score: 0.6618761633081326\n",
            "grid search best param : {'selector__percentile': 27}\n",
            "score on training data : 0.7428427609639463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KQd9SbBC9pg",
        "colab_type": "text"
      },
      "source": [
        "We have reduced overfitting by quite a bit, although it would have been better if this gain had come from increased predictive power rather than reducing the training score. \n",
        "\n",
        "Next, we see a number of very similar words appearing, perhaps suggesting that we should use stemming to improve the fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHur2BVfC9pk",
        "colab_type": "code",
        "outputId": "2eef989d-19e6-44ba-fe13-b93df171c29a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "from nltk.stem.porter import *\n",
        "from nltk import tokenize\n",
        "stemmer = PorterStemmer()\n",
        "tokenizer = tokenize.WordPunctTokenizer()\n",
        "def stemCustom(X):\n",
        "    splitStemJoin = lambda string: ' '.join([stemmer.stem(word) for word in tokenizer.tokenize(string)])\n",
        "    return X.apply(splitStemJoin)\n",
        "\n",
        "stemTransform = FunctionTransformer(stemCustom, validate=False)\n",
        "\n",
        "X_wrangle_4 = stemTransform.fit_transform(X_wrangle_3)\n",
        "X_test_wrangle_4 = stemTransform.transform(X_test_wrangle_3)\n",
        "\n",
        "best_score, best_params, custom_F1 = mostImportantFeatures(X_wrangle_4, genreDF.Comedy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['accident' 'actor' 'advertis' 'advic' 'aircraft' 'aliv' 'ambush'\n",
            " 'announc' 'annoy' 'antic' 'arm' 'armi' 'attack' 'audienc' 'bachelor'\n",
            " 'ball' 'band' 'battl' 'best' 'bet' 'blood' 'boat' 'bodi' 'bong' 'bowl'\n",
            " 'boyfriend' 'brutal' 'bumbl' 'burn' 'busi' 'butler' 'buy' 'cartoon' 'cat'\n",
            " 'chase' 'cheerlead' 'chef' 'child' 'civilian' 'clumsi' 'colleg' 'comedi'\n",
            " 'comic' 'command' 'compani' 'competit' 'contest' 'creatur' 'credit'\n",
            " 'crew' 'crime' 'dad' 'danc' 'dark' 'date' 'daughter' 'dead' 'death'\n",
            " 'decid' 'demon' 'destroy' 'die' 'dinner' 'disguis' 'dog' 'dragon' 'dress'\n",
            " 'drug' 'eccentr' 'embarrass' 'end' 'escap' 'evid' 'fighter' 'flashback'\n",
            " 'forc' 'friend' 'fun' 'game' 'gay' 'girlfriend' 'golf' 'govern' 'group'\n",
            " 'guest' 'gun' 'guy' 'helicopt' 'hockey' 'hotel' 'human' 'hunt' 'idea'\n",
            " 'impress' 'inept' 'infect' 'inform' 'investig' 'invit' 'job' 'joke' 'kid'\n",
            " 'kill' 'killer' 'kiss' 'knife' 'ladi' 'love' 'make' 'man' 'marijuana'\n",
            " 'marri' 'men' 'militari' 'misadventur' 'missil' 'mission' 'mistak'\n",
            " 'misunderstand' 'mom' 'money' 'mous' 'movi' 'murder' 'music' 'mysteri'\n",
            " 'nerd' 'new' 'owner' 'parent' 'parti' 'pay' 'penguin' 'perform' 'plan'\n",
            " 'play' 'polic' 'popular' 'power' 'prison' 'produc' 'product' 'prom'\n",
            " 'protect' 'quit' 'rape' 'reconcil' 'relationship' 'remain' 'restaur'\n",
            " 'roommat' 'salesman' 'scheme' 'school' 'sell' 'sex' 'ship' 'shoot' 'shop'\n",
            " 'shot' 'sing' 'slave' 'sniper' 'soldier' 'son' 'song' 'stab' 'star'\n",
            " 'steal' 'store' 'studio' 'surviv' 'survivor' 'suspect' 'talent' 'think'\n",
            " 'ticket' 'togeth' 'tortur' 'troop' 'victim' 'villag' 'violent' 'virgin'\n",
            " 'viru' 'vision' 'wa' 'waiter' 'war' 'warn' 'weapon' 'wed' 'white' 'win'\n",
            " 'women' 'woo' 'wound' 'year' 'young' 'zoo']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-INiKrIhyyrh",
        "colab_type": "code",
        "outputId": "325c6307-141e-4c89-d502-7fbd167b548a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"Randomized Search best score: {}\".format(best_score))\n",
        "print(\"grid search best param : {}\".format(best_params))\n",
        "print(\"score on training data : {}\".format(custom_F1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Randomized Search best score: 0.6614634830647452\n",
            "grid search best param : {'selector__percentile': 36}\n",
            "score on training data : 0.7198648141194142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16FnEr8nC9pu",
        "colab_type": "text"
      },
      "source": [
        "Again we appear to have reduced overfitting but without improving the actual fit. Let's try looking at a different genre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqeDf2ynC9px",
        "colab_type": "code",
        "outputId": "8748ab46-a2d5-41ba-b9e2-351194126536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "best_score, best_params, custom_F1 = mostImportantFeatures(X_wrangle_4, genreDF.Documentary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['02' '1990' '2000' '2001' '2002' '2003' '2004' '2006' '2007' '2008'\n",
            " '2009' '2010' '2011' '3D' 'accessd' 'activist' 'agre' 'album' 'alleg'\n",
            " 'archiv' 'arriv' 'art' 'ask' 'attack' 'attempt' 'away' 'bailout'\n",
            " 'bassist' 'becom' 'befor' 'began' 'believ' 'billion' 'bodi' 'booksel'\n",
            " 'boy' 'break' 'camera' 'car' 'caus' 'censorship' 'chase' 'chronicl'\n",
            " 'cite' 'clip' 'coalit' 'cochlear' 'com' 'come' 'commentari' 'concert'\n",
            " 'contemporari' 'context' 'contribut' 'controversi' 'convinc' 'coral'\n",
            " 'corpu' 'creativ' 'cub' 'cultur' 'daughter' 'dead' 'decid' 'deficit'\n",
            " 'democraci' 'democrat' 'depict' 'deregul' 'describ' 'die' 'director'\n",
            " 'discov' 'discuss' 'document' 'documentari' 'doe' 'dolphin' 'econom'\n",
            " 'escap' 'ethnic' 'eugen' 'evolut' 'examin' 'excerpt' 'explor' 'fall'\n",
            " 'father' 'featur' 'fight' 'film' 'filmmak' 'flamingo' 'focu' 'focus'\n",
            " 'footag' 'friend' 'genocid' 'girl' 'global' 'goe' 'govern' 'guitarist'\n",
            " 'gun' 'ha' 'head' 'healthcar' 'help' 'hi' 'highlight' 'histor' 'histori'\n",
            " 'home' 'hominid' 'hous' 'html' 'http' 'humpback' 'husband' 'hydrogen'\n",
            " 'includ' 'indi' 'industri' 'insight' 'interspers' 'interview'\n",
            " 'interviewe' 'issu' 'job' 'just' 'kill' 'know' 'krump' 'learn' 'leav'\n",
            " 'lorri' 'love' 'make' 'man' 'manag' 'market' 'marri' 'meet' 'modern'\n",
            " 'montag' 'movement' 'murder' 'music' 'narr' 'nation' 'night' 'offic'\n",
            " 'onli' 'order' 'peopl' 'php' 'plan' 'polic' 'polici' 'polit' 'politician'\n",
            " 'pride' 'profil' 'punk' 'realiz' 'recycl' 'ref' 'repositori' 'return'\n",
            " 'reveal' 'ringsid' 'room' 'run' 'save' 'shoot' 'shown' 'solar' 'son'\n",
            " 'soon' 'stop' 'subcultur' 'technolog' 'tell' 'today' 'tour' 'tourism'\n",
            " 'town' 'tri' 'turn' 'ubiqu' 'union' 'unpreced' 'url' 'verite' 'walru'\n",
            " 'want' 'wetland' 'wife' 'woman' 'www']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg_eEihn1MAP",
        "colab_type": "code",
        "outputId": "53ce0f17-d105-49c0-d3ee-3a63ed05ac3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"Randomized Search best score: {}\".format(best_score))\n",
        "print(\"grid search best param : {}\".format(best_params))\n",
        "print(\"score on training data : {}\".format(custom_F1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Randomized Search best score: 0.385500836937402\n",
            "grid search best param : {'selector__percentile': 22}\n",
            "score on training data : 0.4979291302346986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ForOGRMLC9p2",
        "colab_type": "text"
      },
      "source": [
        "Here the fit is very much worse than for comedy. Also notice notice the presence of numbers which could be a source of error so let's try removing them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT049UyFC9p5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noDigits(X):\n",
        "    return X.str.replace(r'\\d+\\,?\\.?\\d?', \"\")\n",
        "\n",
        "noDigitsTransform = FunctionTransformer(noDigits, validate=False)\n",
        "\n",
        "X_wrangle_5 = noDigitsTransform.fit_transform(X_wrangle_4)\n",
        "X_test_wrangle_5 = noDigitsTransform.transform(X_test_wrangle_4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1MGVO9_C9qC",
        "colab_type": "code",
        "outputId": "99e04b9d-f5c4-4eef-ff14-09e91aef940a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "best_score, best_params, custom_F1 = mostImportantFeatures(X_wrangle_5, genreDF.Documentary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['accessd' 'activist' 'agre' 'album' 'alleg' 'anoth' 'apart' 'archiv'\n",
            " 'arriv' 'art' 'ask' 'attack' 'attempt' 'away' 'bailout' 'bassist' 'becom'\n",
            " 'befor' 'began' 'believ' 'billion' 'bodi' 'booksel' 'boy' 'break'\n",
            " 'camera' 'car' 'caus' 'censorship' 'chase' 'chronicl' 'cite' 'clip'\n",
            " 'coalit' 'cochlear' 'com' 'come' 'commentari' 'concert' 'contemporari'\n",
            " 'context' 'contribut' 'controversi' 'convinc' 'coral' 'corpu' 'creativ'\n",
            " 'cub' 'cultur' 'daughter' 'dead' 'decid' 'deficit' 'democraci' 'democrat'\n",
            " 'depict' 'deregul' 'describ' 'die' 'director' 'discov' 'discuss'\n",
            " 'document' 'documentari' 'doe' 'dolphin' 'drive' 'earli' 'econom' 'escap'\n",
            " 'ethnic' 'eugen' 'evolut' 'examin' 'excerpt' 'explor' 'fall' 'father'\n",
            " 'featur' 'fight' 'film' 'filmmak' 'flamingo' 'focu' 'focus' 'footag'\n",
            " 'friend' 'genocid' 'girl' 'global' 'goe' 'govern' 'guitarist' 'gun' 'ha'\n",
            " 'head' 'healthcar' 'help' 'hi' 'hide' 'highlight' 'histor' 'histori'\n",
            " 'home' 'hominid' 'hous' 'html' 'http' 'humpback' 'husband' 'hydrogen'\n",
            " 'includ' 'indi' 'industri' 'insight' 'interspers' 'interview'\n",
            " 'interviewe' 'issu' 'job' 'just' 'kill' 'know' 'krump' 'learn' 'leav'\n",
            " 'lorri' 'love' 'make' 'man' 'manag' 'market' 'marri' 'meet' 'modern'\n",
            " 'montag' 'mother' 'movement' 'murder' 'music' 'narr' 'nation' 'night'\n",
            " 'offic' 'onli' 'order' 'peopl' 'php' 'plan' 'polar' 'polic' 'polici'\n",
            " 'polit' 'politician' 'pride' 'profil' 'punk' 'realiz' 'recycl' 'ref'\n",
            " 'refus' 'repositori' 'rescu' 'return' 'reveal' 'ringsid' 'room' 'run'\n",
            " 'save' 'send' 'shoot' 'shown' 'solar' 'son' 'soon' 'steal' 'stop'\n",
            " 'subcultur' 'technolog' 'tell' 'today' 'tour' 'tourism' 'town' 'tradit'\n",
            " 'tri' 'trillion' 'turn' 'ubiqu' 'union' 'unpreced' 'url' 'verite' 'walru'\n",
            " 'want' 'western' 'wetland' 'wife' 'woman' 'www']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfhctwHX2leV",
        "colab_type": "code",
        "outputId": "3b0855a8-d0a4-401a-ea5e-ad9aff5a2d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(\"Randomized Search best score: {}\".format(best_score))\n",
        "print(\"grid search best param : {}\".format(best_params))\n",
        "print(\"score on training data : {}\".format(custom_F1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Randomized Search best score: 0.38036962473042824\n",
            "grid search best param : {'selector__percentile': 25}\n",
            "score on training data : 0.5250364608653378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72mLLheIC9qI",
        "colab_type": "text"
      },
      "source": [
        "The fit is the same and, there is a greater amount of overfitting, it makes sense to remove digits from the data set. Finally we need to transform the vectorised synopsis data into an numpy array and then bring all the steps together into a preprocessing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlQC70dpC9qK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transformToNp(X):\n",
        "    return X.values.flatten()\n",
        "\n",
        "transformToNpTransform = FunctionTransformer(transformToNp, validate=False)\n",
        "\n",
        "X_wrangled = transformToNpTransform.fit_transform(X_wrangle_5)\n",
        "X_test_wrangled = transformToNpTransform.transform(X_test_wrangle_5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLbwJclyC9q8",
        "colab_type": "text"
      },
      "source": [
        "# 4. Multilabel Classification Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsTxGmuwSZ8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def averageF1Micro(y, yPredicted, **kwargs):\n",
        "    #if a row in y has no labels assume that its genres were not in the training set and give 0\n",
        "    return np.mean([f1_score(sub_y, sub_ypredicted, labels=[1], average='micro') \n",
        "                    if sum(sub_ypredicted)!=0 else 0 \n",
        "                    for sub_y, sub_ypredicted in zip(y,yPredicted) if sum(sub_y)!=0] )\n",
        "\n",
        "averageF1MicroScorer = make_scorer(averageF1Micro, greater_is_better=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiAokMdQC9q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MinSampleClassifier(BaseEstimator, MetaEstimatorMixin):\n",
        "    def __init__(self, clf=MultinomialNB(), limit=10, decisionFunction=False):\n",
        "        self.clf = clf\n",
        "        self.limit = limit\n",
        "        self.decisionFunction = decisionFunction\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        if sum(y)<self.limit:\n",
        "            self.dataTooSmall_ = True\n",
        "        else:\n",
        "            self.dataTooSmall_ = False\n",
        "            self.clf.fit(X,y)\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        if self.dataTooSmall_:\n",
        "            return np.array([np.array([0.])]*X.shape[0])\n",
        "        else:\n",
        "            return self.clf.predict(X)\n",
        "        \n",
        "    def decision_function(self, X):\n",
        "        if self.dataTooSmall_:\n",
        "            return np.array([np.array([0.])]*X.shape[0])\n",
        "        elif self.decisionFunction:\n",
        "            return self.clf.decision_function(X)\n",
        "        else:\n",
        "            return self.clf.predict_proba(X)[:,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6g4CPNUC9q_",
        "colab_type": "text"
      },
      "source": [
        "Models fall in to two categories. Those, like naive bayes, which can predict the probability that a given data point has a specific label and those that use a decision function.\n",
        "\n",
        "I will create a machine learning algorithm and use it to transform the data into a measure of fit, either a probability or a decision function score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrZPjreyC9rA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PredictionTransformer(BaseEstimator, TransformerMixin, MetaEstimatorMixin):\n",
        "    def __init__(self, clf=MultinomialNB(), decisionFunction=True):\n",
        "        \"\"\"Replaces all features with `clf.predict_proba(X)`\"\"\"\n",
        "        self.clf = clf\n",
        "        self.decisionFunction=decisionFunction\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        self.clf.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.decisionFunction:\n",
        "            return self.clf.decision_function(X)\n",
        "        else:\n",
        "            X_array = np.asarray(X)\n",
        "            probs = self.clf.predict_proba(X)\n",
        "            return [val[:,1] if val.shape[1]==2 else [0]*val.shape[0] for val in probs ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXEAmqnkC9rC",
        "colab_type": "text"
      },
      "source": [
        "Next I will create a class that allows the value of the threshold to be raised or lowered. However this may lead to situations where no labels are predicted. In this case I want to predict the n labels with the highest scores or probabilities, even if those are quite low. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMkqNyf6C9rF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def thresholdCalc(threshold, minCount, x):\n",
        "        #predict values above a threshold or else the most confident minCount\n",
        "    initialThreshold = x>=threshold\n",
        "    if initialThreshold.sum() >=minCount:\n",
        "        return initialThreshold\n",
        "    else:\n",
        "        indexes = np.argpartition(x, -minCount)[-minCount:]\n",
        "        lowerThreshold = x[indexes].min()\n",
        "        if lowerThreshold>0 and minCount<len(x):\n",
        "            return x>=lowerThreshold\n",
        "        else:\n",
        "            return x>0\n",
        "        \n",
        "class ThresholdClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, threshold=0.5, minCount = 2, transpose=True):\n",
        "        \"\"\"Classify samples based on whether they are above of below `threshold`\"\"\"\n",
        "        self.threshold = threshold\n",
        "        self.minCount = minCount\n",
        "        self.transpose=transpose\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        X_array = np.asarray(X)\n",
        "        if self.transpose:\n",
        "            returnVal = np.array([thresholdCalc(self.threshold, self.minCount, sub) for sub in X_array]).T\n",
        "        else:\n",
        "            returnVal = np.array([thresholdCalc(self.threshold, self.minCount, sub) for sub in X_array])\n",
        "        return returnVal\n",
        "    \n",
        "    #This method is required by the OneVsRestClassifier \n",
        "    def predict_proba(self, X):\n",
        "        return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1PNYY6aC9rJ",
        "colab_type": "text"
      },
      "source": [
        "## 5. Defining and tuning models\n",
        "\n",
        "All of the models we are going to try will have a number of parameters that must be tuned using cross validation. Rather than repeat this boiler plate code for each model I will create a simple function that searches the available parameter space for the best values printing out the best results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0ktMbE6C9rK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                  results['mean_test_score'][candidate],\n",
        "                  results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")\n",
        "\n",
        "def crossValidateRandom(X, Y, model, params=None, n_iter=100):\n",
        "    rsCV = RandomizedSearchCV(model, param_distributions=params, n_iter=n_iter,\n",
        "                            scoring=averageF1MicroScorer, verbose=1,cv=10, n_jobs = -1\n",
        "                           )\n",
        "    fittedModel = rsCV.fit(X, Y)\n",
        "    report(rsCV.cv_results_)\n",
        "    return rsCV.best_params_, rsCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvanuPxTC9rW",
        "colab_type": "text"
      },
      "source": [
        "For each model I will use the same function to vectorize the text data, called CountVectorizer. Note that an alternative vectorizer exists, tfIdfVectorizer but with it I have found that the results are not as good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh6UVwzyC9rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = CountVectorizer(lowercase=False, strip_accents='unicode', stop_words='english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_dOehwFC9rb",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes\n",
        "\n",
        "This model is a staple of any attempt at text analysis. For this model I will create a naive bayes model for each genre and then use the threshold predictor to find the most likely labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8kH5kS3C9rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class logUniform():\n",
        "    def __init__(self, low = -9, high = 0):\n",
        "        self.rng = sp_uniform(low, high-low) #This distribution is constant between `loc` and ``loc + scale``.\n",
        "        \n",
        "    def rvs(self, **kwargs):\n",
        "        return 10**(self.rng.rvs(**kwargs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6htwOShC9rg",
        "colab_type": "text"
      },
      "source": [
        "The model first vectorizes the data. Then for each label it selects the most important features and then applies Naive Bayes. Thresholding is then used to predict the best labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFeMdA5xC9rh",
        "colab_type": "code",
        "outputId": "3c689369-7108-4cb4-f3a8-68cf680ffa5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "selectThenNBPipe = Pipeline([(\"selector\", SelectPercentile(chi2)),\n",
        "                             (\"prediction\",MultinomialNB())])\n",
        "\n",
        "multipleNB = OneVsRestClassifier(MinSampleClassifier(selectThenNBPipe, decisionFunction=False))\n",
        "\n",
        "naiveBayes = Pipeline([(\"count\",count), \n",
        "                       (\"model\", PredictionTransformer(clf=multipleNB)),\n",
        "                       (\"threshold\", ThresholdClassifier(transpose=False))])\n",
        "\n",
        "NBparams = {\"count__max_df\":sp_uniform(0.8, 1.0),\n",
        "            \"count__min_df\":sp_randint(1,4),\n",
        "            \"model__clf__estimator__clf__prediction__alpha\":logUniform(low=-12, high=0),\n",
        "            \"model__clf__estimator__clf__prediction__fit_prior\":[True, False],\n",
        "            \"model__clf__estimator__clf__selector__percentile\":sp_randint(1, 100),\n",
        "            \"threshold__threshold\":sp_uniform(0, 0.5),\n",
        "            \"threshold__minCount\":sp_randint(2, 6)\n",
        "           }\n",
        "\n",
        "NBModelBestParams, NaveModel = crossValidateRandom(X_wrangled, y_train, naiveBayes, params=NBparams, n_iter=25)\n",
        "naiveBayes.set_params(**NBModelBestParams)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 26.8min\n",
            "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 33.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model with rank: 1\n",
            "Mean validation score: 0.520 (std: 0.003)\n",
            "Parameters: {'count__max_df': 1.3613949363320534, 'count__min_df': 2, 'model__clf__estimator__clf__prediction__alpha': 0.0004730984482828063, 'model__clf__estimator__clf__prediction__fit_prior': True, 'model__clf__estimator__clf__selector__percentile': 87, 'threshold__minCount': 3, 'threshold__threshold': 0.1597052108949124}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.518 (std: 0.003)\n",
            "Parameters: {'count__max_df': 1.2542236009275753, 'count__min_df': 3, 'model__clf__estimator__clf__prediction__alpha': 2.7412550728534626e-05, 'model__clf__estimator__clf__prediction__fit_prior': True, 'model__clf__estimator__clf__selector__percentile': 52, 'threshold__minCount': 2, 'threshold__threshold': 0.25416874374535425}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.495 (std: 0.003)\n",
            "Parameters: {'count__max_df': 1.1320039384299772, 'count__min_df': 2, 'model__clf__estimator__clf__prediction__alpha': 1.6400708433775654e-05, 'model__clf__estimator__clf__prediction__fit_prior': True, 'model__clf__estimator__clf__selector__percentile': 30, 'threshold__minCount': 4, 'threshold__threshold': 0.23551500516226842}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('count',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=False,\n",
              "                                 max_df=1.3613949363320534, max_features=None,\n",
              "                                 min_df=2, ngram_range=(1, 1),\n",
              "                                 preprocessor=None, stop_words='english',\n",
              "                                 strip_accents='unicode',\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 to...\n",
              "                                                                                                                  SelectPercentile(percentile=87,\n",
              "                                                                                                                                   score_func=<function chi2 at 0x7fb2b0333268>)),\n",
              "                                                                                                                 ('prediction',\n",
              "                                                                                                                  MultinomialNB(alpha=0.0004730984482828063,\n",
              "                                                                                                                                class_prior=None,\n",
              "                                                                                                                                fit_prior=True))],\n",
              "                                                                                                          verbose=False),\n",
              "                                                                                             decisionFunction=False,\n",
              "                                                                                             limit=10),\n",
              "                                                               n_jobs=None),\n",
              "                                       decisionFunction=True)),\n",
              "                ('threshold',\n",
              "                 ThresholdClassifier(minCount=3, threshold=0.1597052108949124,\n",
              "                                     transpose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIZnemMVq4M3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NaveBayesModel = NaveModel.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWN6Bm4RoxqD",
        "colab_type": "text"
      },
      "source": [
        "Results for Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XczOWq3iy1lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-ny2j1ho0a6",
        "colab_type": "code",
        "outputId": "74a6ad63-8771-4604-bb88-9f0dc7116750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_pred = NaveModel.predict(X_test_wrangled)\n",
        "print(\"Average Micro F1 Score: {}\".format(averageF1Micro(y_test, y_pred)))\n",
        "print(\"Precision Score: {}\".format(precision_score(y_test, y_pred, average='micro')))\n",
        "print(\"Recall Score: {}\".format(recall_score(y_test, y_pred, average='micro')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Micro F1 Score: 0.5235301471124361\n",
            "Precision Score: 0.4299866641265003\n",
            "Recall Score: 0.6804854149393231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghKWM2AIC9ro",
        "colab_type": "text"
      },
      "source": [
        "We see a best cross validation score of 0.520 for the naive bayes model. This is a good result but we should still experiment with different models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K30jCXXaC9rq",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "This model is easier to apply than naive bayes since it natively copes with multiple labels. This model was very slow to fit in the presence of so 1000's of features. I found the best results came not when I found the best subset of features but instead by performing Singular Value Decomposition on the features, reducing the number of dimensions down to 100. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D14aqBrtC9rr",
        "colab_type": "code",
        "outputId": "fe7afd73-8999-4e82-c183-a6bfe3bb037a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "randomForest = Pipeline([(\"count\", count),\n",
        "                         (\"TruncatedSVD\", TruncatedSVD(n_components=100)),\n",
        "                         (\"model\", PredictionTransformer(clf=RandomForestClassifier(), decisionFunction=False)), \n",
        "                         (\"prob\", ThresholdClassifier())\n",
        "                        ])\n",
        "\n",
        "multiRFParams={\n",
        "               \"model__clf__n_estimators\":[15, 20, 25], \n",
        "               \"model__clf__max_depth\":[10, 20, 25], \n",
        "               \"model__clf__min_samples_split\":[3,5,7],\n",
        "               \"prob__threshold\":[0.4, 0.5],\n",
        "               \"prob__minCount\":[2,3,4]\n",
        "              }\n",
        "\n",
        "randomRFParams={\n",
        "                \"count__max_df\":sp_uniform(0.8, 1.0),\n",
        "                \"count__min_df\":sp_randint(1,4),\n",
        "                \"model__clf__n_estimators\":sp_randint(10, 30),\n",
        "                \"model__clf__max_depth\":sp_randint(5, 50),\n",
        "                \"model__clf__min_samples_split\":sp_randint(2, 8),\n",
        "                \"prob__threshold\":sp_uniform(0, 0.5),\n",
        "                \"prob__minCount\":sp_randint(2, 6)\n",
        "               }\n",
        "\n",
        "randomForestBestParams, Random_Model = crossValidateRandom(X_wrangled, y_train, randomForest, \n",
        "                                             params=randomRFParams, n_iter=15)\n",
        "randomForest.set_params(**randomForestBestParams)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 20.8min\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 57.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model with rank: 1\n",
            "Mean validation score: 0.464 (std: 0.004)\n",
            "Parameters: {'count__max_df': 0.9441002189941308, 'count__min_df': 3, 'model__clf__max_depth': 20, 'model__clf__min_samples_split': 7, 'model__clf__n_estimators': 28, 'prob__minCount': 3, 'prob__threshold': 0.1883523963953463}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.461 (std: 0.004)\n",
            "Parameters: {'count__max_df': 1.3792066514765775, 'count__min_df': 2, 'model__clf__max_depth': 12, 'model__clf__min_samples_split': 4, 'model__clf__n_estimators': 22, 'prob__minCount': 2, 'prob__threshold': 0.23680001101598058}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.455 (std: 0.005)\n",
            "Parameters: {'count__max_df': 1.689132894788194, 'count__min_df': 1, 'model__clf__max_depth': 12, 'model__clf__min_samples_split': 2, 'model__clf__n_estimators': 15, 'prob__minCount': 5, 'prob__threshold': 0.20714282610509355}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('count',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=False,\n",
              "                                 max_df=0.9441002189941308, max_features=None,\n",
              "                                 min_df=3, ngram_range=(1, 1),\n",
              "                                 preprocessor=None, stop_words='english',\n",
              "                                 strip_accents='unicode',\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 to...\n",
              "                                                                  max_samples=None,\n",
              "                                                                  min_impurity_decrease=0.0,\n",
              "                                                                  min_impurity_split=None,\n",
              "                                                                  min_samples_leaf=1,\n",
              "                                                                  min_samples_split=7,\n",
              "                                                                  min_weight_fraction_leaf=0.0,\n",
              "                                                                  n_estimators=28,\n",
              "                                                                  n_jobs=None,\n",
              "                                                                  oob_score=False,\n",
              "                                                                  random_state=None,\n",
              "                                                                  verbose=0,\n",
              "                                                                  warm_start=False),\n",
              "                                       decisionFunction=False)),\n",
              "                ('prob',\n",
              "                 ThresholdClassifier(minCount=3, threshold=0.1883523963953463,\n",
              "                                     transpose=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlQUEIet0VbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Random_Forest_Model = Random_Model.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mpO3QIdYdZi",
        "colab_type": "text"
      },
      "source": [
        "Results for Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IizRfpecw3M",
        "colab_type": "code",
        "outputId": "719f965f-06d9-49c5-906d-b0be62226c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_test_wrangled = preprocessing.transform(X_test)\n",
        "y_pred = Random_Forest_Model.predict(X_test_wrangled)\n",
        "print(\"Average Micro F1 Score: {}\".format(averageF1Micro(y_test, y_pred)))\n",
        "print(\"Precision Score: {}\".format(precision_score(y_test, y_pred, average='micro')))\n",
        "print(\"Recall Score: {}\".format(recall_score(y_test, y_pred, average='micro')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Micro F1 Score: 0.46591851711112275\n",
            "Precision Score: 0.395722993904267\n",
            "Recall Score: 0.5969699253787594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVnLQrf1ZXlm",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes is the better model than Random Forest due to high F1 Score. F1 Score is beneficial in multilabel classification, when there is uneven class distribution"
      ]
    }
  ]
}